{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz8vr4yo33d3"
      },
      "source": [
        "# This file is for inference\n",
        "#### postprocessing + ensemble 3 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1fKtDPX5N5J",
        "outputId": "98e9a3b2-16ac-4089-a2bc-7fbb1eb1943b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g5wPfsX32OLZR5G8iqg_C54RnxIiAtp6_Uz8gTajht_PDY78QHnKAo\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwcqkAgw4DSi"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTHDK4xe4LwS"
      },
      "source": [
        "class TIMITDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = torch.from_numpy(X).float()\n",
        "        if y is not None:\n",
        "            y = y.astype(np.int)\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_wiuSwl4OA3"
      },
      "source": [
        "def get_device():\n",
        "  return 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AonF-SEC4UxC"
      },
      "source": [
        "### Model Structures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBkbQ5-e4Rx5"
      },
      "source": [
        "########### model1 ###############\n",
        "class BasicBlock01(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, p=0.5):\n",
        "        super(BasicBlock01, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(p),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "class Classifier01(nn.Module):\n",
        "    def __init__(self, input_dim=429, output_dim=39, hidden_layers=5, hidden_dim=2048):\n",
        "        super(Classifier01, self).__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            BasicBlock01(input_dim, hidden_dim),\n",
        "            *[BasicBlock01(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kmgKupz4WTE"
      },
      "source": [
        "########### model2 ###############\n",
        "class BasicBlock02(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, p=0.5):\n",
        "        super(BasicBlock02, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.Dropout(p),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "class Classifier02(nn.Module):\n",
        "    def __init__(self, input_dim=429, output_dim=39, hidden_layers=5, hidden_dim=2048):\n",
        "        super(Classifier02, self).__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            BasicBlock02(input_dim, hidden_dim),\n",
        "            *[BasicBlock02(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAAhhN-T4YC7"
      },
      "source": [
        "########### model3 ###############\n",
        "class BasicBlock03(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, p=0.5):\n",
        "        super(BasicBlock03, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "class Classifier03(nn.Module):\n",
        "    def __init__(self, input_dim=429, output_dim=39, hidden_layers=6, hidden_dim=2048):\n",
        "        super(Classifier03, self).__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            BasicBlock03(input_dim, hidden_dim),\n",
        "            *[BasicBlock03(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCjJaSzJ-z1K"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYtlNpEg4aAz"
      },
      "source": [
        "def inference(model, device):\n",
        "    predict = []\n",
        "    model.eval() # set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader):\n",
        "            inputs = data\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "\n",
        "            for y in test_pred.cpu().numpy():\n",
        "                predict.append(y)\n",
        "    return predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7BXnpH74byr"
      },
      "source": [
        "def postprocess(predict):\n",
        "    cur_phone = predict[0]\n",
        "    count = 1\n",
        "\n",
        "    for i in range(1,len(predict)):\n",
        "        if predict[i] == cur_phone:\n",
        "            count += 1\n",
        "        else:\n",
        "            if count>3:\n",
        "                count = 1\n",
        "            else:\n",
        "                if predict[i]==predict[i-count-1]:\n",
        "                    predict[i-count:i] = predict[i]\n",
        "                    tmp = 0\n",
        "                    k = i-count-2\n",
        "                    while predict[k] == predict[i]:\n",
        "                        tmp += 1\n",
        "                        k -= 1\n",
        "                    count += tmp\n",
        "                else:\n",
        "                    count = 1\n",
        "            cur_phone = predict[i]\n",
        "    return predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3SjFUp-4dq4"
      },
      "source": [
        "def ensemble(preds):\n",
        "    print('ensemble...')\n",
        "    new_val = []\n",
        "    for i in range(test.shape[0]):\n",
        "        x = preds[:,i]\n",
        "        m = np.bincount(x).argmax()\n",
        "        new_val.append(m)\n",
        "    \n",
        "    return new_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZmNx53C4fyq"
      },
      "source": [
        "def main():\n",
        "    device = get_device()\n",
        "    #model1\n",
        "    print('Loading model 1...')\n",
        "    net01 = Classifier01().to(device)\n",
        "    net01.load_state_dict(torch.load('/content/drive/MyDrive/checkpoints/model_01.ckpt'))#YOUR MODEL1 PATH HERE\n",
        "    #model2\n",
        "    print('Loading model 2...')\n",
        "    net02 = Classifier02().to(device)\n",
        "    net02.load_state_dict(torch.load('/content/drive/MyDrive/checkpoints/model_02.ckpt'))#YOUR MODEL2 PATH HERE\n",
        "    #model3\n",
        "    print('Loading model 3...')\n",
        "    net03 = Classifier03().to(device)\n",
        "    net03.load_state_dict(torch.load('/content/drive/MyDrive/checkpoints/model_03.ckpt'))#YOUR MODEL3 PATH HERE\n",
        "    \n",
        "    print('predicting using model 1...')\n",
        "    f1 = inference(net01, device)\n",
        "    f1 = postprocess(np.array(f1))\n",
        "    print('predicting using model 2...')\n",
        "    f2 = inference(net02, device)\n",
        "    f2 = postprocess(np.array(f2))\n",
        "    print('predicting using model 3...')\n",
        "    f3 = inference(net03, device)\n",
        "    f3 = postprocess(np.array(f3))\n",
        "\n",
        "    new_val = ensemble(np.array([f1,f2,f3]))\n",
        "\n",
        "    print('writing prediction to output.csv.')\n",
        "    with open(\"output.csv\", 'w') as f:\n",
        "        f.write('Id,Class\\n')\n",
        "        for i, y in  enumerate(new_val):\n",
        "            f.write('{},{}\\n'.format(i, y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kikAGqS_4iBF"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "data_root='/content/drive/MyDrive/timit_11/'\n",
        "test = np.load(data_root + 'test_11.npy')\n",
        "test_set = TIMITDataset(test, None)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk_PqCpQ8dx-",
        "outputId": "5b5e6271-4bdc-4913-8b13-f4f3215f8c53"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model 1...\n",
            "Loading model 2...\n",
            "Loading model 3...\n",
            "predicting using model 1...\n",
            "predicting using model 2...\n",
            "predicting using model 3...\n",
            "ensemble...\n",
            "writing prediction to output.csv.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}